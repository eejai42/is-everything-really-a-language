<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Substrate Report: english</title>
    <style>
:root {
    --bg-primary: #ffffff; --bg-secondary: #f8f9fa; --bg-tertiary: #e9ecef;
    --text-primary: #212529; --text-secondary: #6c757d; --border-color: #dee2e6;
    --accent-color: #0d6efd; --success-color: #198754; --warning-color: #ffc107;
    --danger-color: #dc3545; --code-bg: #f6f8fa; --shadow: 0 2px 8px rgba(0,0,0,0.1); --radius: 6px;
}
[data-theme="dark"] {
    --bg-primary: #1a1a2e; --bg-secondary: #16213e; --bg-tertiary: #0f3460;
    --text-primary: #eaeaea; --text-secondary: #b0b0b0; --border-color: #3a3a5c;
    --accent-color: #4dabf7; --success-color: #51cf66; --warning-color: #fcc419;
    --danger-color: #ff6b6b; --code-bg: #0d1117; --shadow: 0 2px 8px rgba(0,0,0,0.3);
}
* { margin: 0; padding: 0; box-sizing: border-box; }
body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; background: var(--bg-secondary); color: var(--text-primary); line-height: 1.5; min-height: 100vh; }
header { background: var(--bg-primary); border-bottom: 1px solid var(--border-color); padding: 0.75rem 1rem; display: flex; justify-content: space-between; align-items: center; }
.header-left { display: flex; align-items: center; gap: 0.75rem; }
.substrate-icon { font-size: 1.5rem; }
h1 { font-size: 1.1rem; font-weight: 600; }
.header-stats { display: flex; gap: 1rem; font-size: 0.8rem; }
.stat { display: flex; align-items: center; gap: 0.25rem; }
.stat-value { font-weight: 600; }
.score-perfect, .score-good { color: var(--success-color); }
.score-warning { color: var(--warning-color); }
.score-danger { color: var(--danger-color); }
#theme-toggle { background: var(--bg-tertiary); border: 1px solid var(--border-color); border-radius: 50%; width: 28px; height: 28px; cursor: pointer; display: flex; align-items: center; justify-content: center; font-size: 0.9rem; }
#theme-toggle:hover { background: var(--accent-color); color: white; }
#theme-toggle .moon { display: none; }
[data-theme="dark"] #theme-toggle .sun { display: none; }
[data-theme="dark"] #theme-toggle .moon { display: inline; }
.tabs { display: flex; background: var(--bg-primary); border-bottom: 1px solid var(--border-color); overflow-x: auto; padding: 0 0.5rem; }
.tab { background: none; border: none; padding: 0.5rem 1rem; cursor: pointer; font-size: 0.8rem; color: var(--text-secondary); border-bottom: 2px solid transparent; white-space: nowrap; }
.tab:hover { color: var(--text-primary); }
.tab.active { color: var(--accent-color); border-bottom-color: var(--accent-color); font-weight: 500; }
main { padding: 1rem; }
.tab-content { display: none; }
.tab-content.active { display: block; animation: fadeIn 0.2s ease; }
@keyframes fadeIn { from { opacity: 0; } to { opacity: 1; } }
.card { background: var(--bg-primary); border: 1px solid var(--border-color); border-radius: var(--radius); padding: 1rem; margin-bottom: 1rem; box-shadow: var(--shadow); }
.card h2 { font-size: 0.9rem; font-weight: 600; margin-bottom: 0.75rem; }
pre { background: var(--code-bg); border: 1px solid var(--border-color); border-radius: var(--radius); padding: 0.75rem; overflow-x: auto; font-family: 'SF Mono', Monaco, monospace; font-size: 0.75rem; line-height: 1.4; max-height: 500px; overflow-y: auto; }
.code-info { font-size: 0.75rem; color: var(--text-secondary); margin-bottom: 0.5rem; }
.markdown-content { line-height: 1.7; }
.markdown-content h2 { font-size: 1.1rem; font-weight: 600; margin: 1.5rem 0 0.75rem 0; border-bottom: 1px solid var(--border-color); padding-bottom: 0.5rem; }
.markdown-content h3 { font-size: 1rem; font-weight: 600; margin: 1.25rem 0 0.5rem 0; }
.markdown-content h4 { font-size: 0.9rem; font-weight: 600; margin: 1rem 0 0.5rem 0; color: var(--text-secondary); }
.markdown-content p { margin-bottom: 0.75rem; }
.markdown-content ul { margin-left: 1.5rem; margin-bottom: 0.75rem; }
.markdown-content li { margin-bottom: 0.35rem; }
.markdown-content pre { margin: 0.75rem 0; }
.markdown-content strong { font-weight: 600; }
.results-summary { display: flex; gap: 1.5rem; flex-wrap: wrap; margin-bottom: 1rem; }
.result-item { text-align: center; }
.result-value { font-size: 1.5rem; font-weight: 700; }
.result-label { font-size: 0.7rem; color: var(--text-secondary); text-transform: uppercase; }
.prose-container { max-height: 600px; overflow-y: auto; padding-right: 0.5rem; }
    </style>
</head>
<body>
    <header>
        <div class="header-left">
            <span class="substrate-icon">üìù</span>
            <h1>English (NLG) Execution Substrate</h1>
        </div>
        <div class="header-stats">
            <div class="stat"><span>Score:</span><span class="stat-value score-warning">64.1%</span></div>
            <div class="stat"><span>118/184 passed</span></div>
        </div>
        <button id="theme-toggle" title="Toggle theme"><span class="sun">‚òÄÔ∏è</span><span class="moon">üåô</span></button>
    </header>
    <nav class="tabs">
        <button class="tab active" data-tab="description">Description</button>
        <button class="tab" data-tab="log">Run Log</button>
        <button class="tab" data-tab="results">Test Results</button>
        <button class="tab" data-tab="specification">Specification</button>
    </nav>
    <main>
        <div id="description" class="tab-content active">
            <div class="card">
                <h2>What This Substrate Does</h2>
                <div class="markdown-content">
                    <p>The English substrate tests whether <strong>plain English can serve as an execution substrate</strong>. It uses a two-step LLM flow:</p>
                    <h3>Two-Step LLM Architecture</h3>
                    <ol>
                        <li><strong>Inject</strong>: <code>inject-into-english.py</code> sends the rulebook JSON to an LLM, which writes a plain English specification explaining how to compute each calculated field</li>
                        <li><strong>Take Test</strong>: <code>take-test.py</code> sends the English specification + test data to an LLM, which computes the calculated field values by following the English instructions</li>
                    </ol>
                    <p><strong>Zero formula parsing.</strong> The LLM reads formulas natively and explains them better than regex could.</p>
                </div>
            </div>
            <div class="card">
                <h2>Key Features</h2>
                <ul class="markdown-content">
                    <li><strong>Generic</strong>: Works with ANY rulebook - no domain-specific hardcoding</li>
                    <li><strong>LLM-Driven</strong>: Specification generated by LLM, not template strings</li>
                    <li><strong>Round-Trip Testing</strong>: Verifies the English spec is clear enough to compute correct values</li>
                    <li><strong>Minimal Code</strong>: ~130 lines total, down from ~425 lines</li>
                </ul>
            </div>
        </div>
        <div id="log" class="tab-content">
            <div class="card">
                <h2>Execution Log</h2>
                <div class="code-info">Last run: Tue Feb 24 02:16:00 CST 2026</div>
                <pre>=== English (LLM) Substrate Test Run ===
Started: Tue Feb 24 02:16:00 CST 2026

english: English documents not found, running injection first...
english: This will generate glossary.md and specification.md via LLM

Generating english substrate...
  Loaded rulebook: PUBLISHED - ERB_semiotics-is-everything-a-language

=== Generating Specification (LLM-driven) ===
  Generating specification via LLM...
  Calling OPENAI (gpt-4o-mini)...
  Created specification.md

Done generating english substrate.

english: Injection complete, now running test...

======================================================================
English Execution Substrate - LLM Test Execution
Using ENGLISH PROSE documents (glossary.md, specification.md)
======================================================================

Loading English specification documents...
  Loaded specification.md (6533 chars)

Loading rulebook for schema metadata...
Discovered 3 entities: LanguageCandidates, IsEverythingALanguage, ERBCustomizations

Processing language_candidates...
  Schema: 26 fields, 8 calculated
    Using English prose documents (specification)
============================================================
PROMPT (first 2 lines):
  You are taking a test. Your task is to fill in the computed columns for each record based on the Eng
  
  ... (790 total lines, 28078 chars)
============================================================
Calling OpenAI (gpt-4o-mini)... please wait...
============================================================
RESPONSE (first 2 lines):
  ```json
  [
  ... (648 total lines, 25064 chars)
============================================================
  -&gt; language_candidates: 23 records, 184 computed fields filled

======================================================================
English substrate: Processed 1 entities, 23 total records
Filled 184 computed fields total
======================================================================

Completed: Tue Feb 24 02:20:24 CST 2026
</pre>
            </div>
        </div>
        <div id="results" class="tab-content">
            <div class="card">
                <h2>Test Summary</h2>
                <div class="results-summary">
                    <div class="result-item"><div class="result-value score-warning">64.1%</div><div class="result-label">Score</div></div>
                    <div class="result-item"><div class="result-value score-perfect">118</div><div class="result-label">Passed</div></div>
                    <div class="result-item"><div class="result-value">66</div><div class="result-label">Failed</div></div>
                    <div class="result-item"><div class="result-value">184</div><div class="result-label">Total</div></div>
                </div>
            </div>
        </div>
        <div id="specification" class="tab-content">
            <div class="card">
                <h2>specification.md (LLM-Generated)</h2>
                <div class="prose-container markdown-content"><h2>Specification Document for Rulebook: PUBLISHED - ERB_semiotics-is-everything-a-language</h2>
<h3>Overview</h3>
<p>This rulebook defines a set of criteria and calculated fields to classify various entities as language candidates based on specific properties. It is derived from an Airtable base and includes various entities with attributes that help determine whether something qualifies as a language. The calculated fields derive their values from raw input fields, allowing for automated assessments based on defined logical conditions.</p>
<h3>LanguageCandidates</h3>
<h4>Input Fields</h4>
<p>1. <strong>LanguageCandidateId</strong></p>
<p>   - <strong>Type:</strong> string</p>
<p>   - <strong>Description:</strong> Unique identifier for the language candidate.</p>
<p>2. <strong>Name</strong></p>
<p>   - <strong>Type:</strong> string</p>
<p>   - <strong>Description:</strong> Name of the language candidate being classified.</p>
<p>3. <strong>HasSyntax</strong></p>
<p>   - <strong>Type:</strong> boolean</p>
<p>   - <strong>Description:</strong> Indicates whether the language candidate has syntax and/or grammar.</p>
<p>4. <strong>CanBeHeld</strong></p>
<p>   - <strong>Type:</strong> boolean</p>
<p>   - <strong>Description:</strong> Indicates if the candidate is physical/material and could theoretically be held.</p>
<p>5. <strong>DistanceFromConcept</strong></p>
<p>   - <strong>Type:</strong> integer</p>
<p>   - <strong>Description:</strong> Numeric representation of how far the candidate is from the core concept of a language.</p>
<p>6. <strong>IsLanguage</strong></p>
<p>   - <strong>Type:</strong> boolean</p>
<p>   - <strong>Description:</strong> Indicates if the candidate is classified as a language.</p>
<h4>Calculated Fields</h4>
<p>1. <strong>HasGrammar</strong></p>
<p>   - <strong>Description:</strong> Indicates if the candidate has grammar, generally inferred from the presence of syntax.</p>
<p>   - <strong>Calculation:</strong> This field is true if `HasSyntax` is true.</p>
<p>   - <strong>Formula:</strong> `={{HasSyntax}} = TRUE()`</p>
<p>   - <strong>Example:</strong> If `HasSyntax` is true, then `HasGrammar` will also be true.</p>
<p>2. <strong>Question</strong></p>
<p>   - <strong>Description:</strong> A question formatted for a Family Feud style poll.</p>
<p>   - <strong>Calculation:</strong> The question is constructed by concatenating "Is " with the `Name` of the candidate and appending " a language?".</p>
<p>   - <strong>Formula:</strong> `="Is " & {{Name}} & " a language?"`</p>
<p>   - <strong>Example:</strong> For a candidate named "English", the question would be "Is English a language?".</p>
<p>3. <strong>PredictedAnswer</strong></p>
<p>   - <strong>Description:</strong> The predicted answer based on a combination of properties that suggest whether the candidate is a language.</p>
<p>   - <strong>Calculation:</strong> This field is true if all of the following conditions are met:</p>
<p>     - `HasSyntax` is true</p>
<p>     - `RequiresParsing` is true</p>
<p>     - `IsDescriptionOf` is true</p>
<p>     - `HasLinearDecodingPressure` is true</p>
<p>     - `ResolvesToAnAST` is true</p>
<p>     - `IsStableOntologyReference` is true</p>
<p>     - `CanBeHeld` is false</p>
<p>     - `HasIdentity` is false</p>
<p>   - <strong>Formula:</strong> `=AND({{HasSyntax}}, {{RequiresParsing}}, {{IsDescriptionOf}}, {{HasLinearDecodingPressure}}, {{ResolvesToAnAST}}, {{IsStableOntologyReference}}, NOT({{CanBeHeld}}), NOT({{HasIdentity}}))`</p>
<p>   - <strong>Example:</strong> For "English", if all conditions are met, `PredictedAnswer` would be true.</p>
<p>4. <strong>PredictionPredicates</strong></p>
<p>   - <strong>Description:</strong> A string summarizing the predicates that led to the predicted answer.</p>
<p>   - <strong>Calculation:</strong> This field concatenates multiple conditions into a descriptive string.</p>
<p>   - <strong>Formula:</strong> </p>
<p>     ```</p>
<p>     =IF({{HasSyntax}}, "Has Syntax", "No Syntax") & " & " & IF({{RequiresParsing}}, "Requires Parsing", "No Parsing Needed") & " & " & IF({{IsDescriptionOf}}, "Describes the thing", "Is the Thing") & " & " & IF({{HasLinearDecodingPressure}}, "Has Linear Decoding Pressure", "No Decoding Pressure") & " & " & IF({{ResolvesToAnAST}}, "Resolves to AST", "No AST") & ", " & IF({{IsStableOntologyReference}}, "Is Stable Ontology", "Not 'Ontology'") & " AND " & IF({{CanBeHeld}}, "Can Be Held", "Can't Be Held") & ", " & IF({{HasIdentity}}, "Has Identity", "Has no Identity")</p>
<p>     ```</p>
<p>   - <strong>Example:</strong> For "English", the output might be "Has Syntax & Requires Parsing & Describes the thing & Has Linear Decoding Pressure & Resolves to AST, Is Stable Ontology AND Can't Be Held, Has no Identity".</p>
<p>5. <strong>PredictionFail</strong></p>
<p>   - <strong>Description:</strong> Provides an explanation if the predicted answer does not match the candidate's status.</p>
<p>   - <strong>Calculation:</strong> If `PredictedAnswer` does not equal `IsLanguage`, it constructs a message indicating the mismatch and flags any open/closed world conflicts.</p>
<p>   - <strong>Formula:</strong> </p>
<p>     ```</p>
<p>     =IF(NOT({{PredictedAnswer}} = {{IsLanguage}}), {{Name}} & " " & IF({{PredictedAnswer}}, "Is", "Isn't") & " a Family Feud Language, but " & IF({{IsLanguage}}, "Is", "Is Not") & " marked as a 'Language Candidate.'", "") & IF({{IsOpenClosedWorldConflicted}}, " - Open World vs. Closed World Conflict.", "")</p>
<p>     ```</p>
<p>   - <strong>Example:</strong> For "A Coffee Mug", if `PredictedAnswer` is false and `IsLanguage` is true, the output would be "A Coffee Mug Is not a Family Feud Language, but Is marked as a 'Language Candidate.'".</p>
<p>6. <strong>IsDescriptionOf</strong></p>
<p>   - <strong>Description:</strong> Indicates if the candidate describes the concept based on its distance from the core concept.</p>
<p>   - <strong>Calculation:</strong> This field is true if `DistanceFromConcept` is greater than 1.</p>
<p>   - <strong>Formula:</strong> `={{DistanceFromConcept}} > 1`</p>
<p>   - <strong>Example:</strong> If `DistanceFromConcept` is 2, `IsDescriptionOf` would be true.</p>
<p>7. <strong>IsOpenClosedWorldConflicted</strong></p>
<p>   - <strong>Description:</strong> Indicates if there is a conflict between being classified as both open and closed world.</p>
<p>   - <strong>Calculation:</strong> This field is true if both `IsOpenWorld` and `IsClosedWorld` are true.</p>
<p>   - <strong>Formula:</strong> `=AND({{IsOpenWorld}}, {{IsClosedWorld}})`</p>
<p>   - <strong>Example:</strong> If both `IsOpenWorld` and `IsClosedWorld` are true, then `IsOpenClosedWorldConflicted` will be true.</p>
<p>8. <strong>RelationshipToConcept</strong></p>
<p>   - <strong>Description:</strong> Indicates the relationship of the candidate to the core concept.</p>
<p>   - <strong>Calculation:</strong> If `DistanceFromConcept` equals 1, it outputs "IsMirrorOf"; otherwise, it outputs "IsDescriptionOf".</p>
<p>   - <strong>Formula:</strong> `=IF({{DistanceFromConcept}} = 1, "IsMirrorOf", "IsDescriptionOf")`</p>
<p>   - <strong>Example:</strong> If `DistanceFromConcept` is 1 for "A Coffee Mug", the output would be "IsMirrorOf".</p>
<h3>Conclusion</h3>
<p>This specification document provides a comprehensive guide to understanding how to compute the calculated fields for the language candidates defined in the rulebook. By following the outlined steps and formulas, one can accurately derive the necessary values from the raw input fields.</p></div>
            </div>
        </div>
    </main>
    <script>
const themeToggle = document.getElementById('theme-toggle');
const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
function getInitialTheme() { try { if (window.parent && window.parent.document.documentElement.dataset.theme) return window.parent.document.documentElement.dataset.theme; } catch (e) {} return prefersDark ? 'dark' : 'light'; }
document.documentElement.dataset.theme = getInitialTheme();
themeToggle.addEventListener('click', () => { document.documentElement.dataset.theme = document.documentElement.dataset.theme === 'dark' ? 'light' : 'dark'; });
window.addEventListener('message', (event) => { if (event.data.type === 'theme-change') document.documentElement.dataset.theme = event.data.theme; });
document.querySelectorAll('.tab').forEach(tab => { tab.addEventListener('click', () => { document.querySelectorAll('.tab').forEach(t => t.classList.remove('active')); document.querySelectorAll('.tab-content').forEach(c => c.classList.remove('active')); tab.classList.add('active'); document.getElementById(tab.dataset.tab).classList.add('active'); }); });
    </script>
</body>
</html>